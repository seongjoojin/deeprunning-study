{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10MNIST.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1siaXTlSN6MtbX3Owzo0soW47S-LNPBVr",
          "timestamp": 1521533386168
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Wd7b8Ee-1sqD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 32
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "outputId": "c2829e5f-d41c-4807-83d1-b4fbe387d164",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521533682140,
          "user_tz": -540,
          "elapsed": 271015,
          "user": {
            "displayName": "sj jin",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "107618035827318999649"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# 머신러닝 학습의 Hello World 와 같은 MNIST(손글씨 숫자 인식) 문제를 신경망으로 풀어봅니다.\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
        "\n",
        "#########\n",
        "# 옵션 설정\n",
        "######\n",
        "learning_rate = 0.001\n",
        "total_epoch = 30\n",
        "batch_size = 128\n",
        "\n",
        "# RNN 은 순서가 있는 자료를 다루므로,\n",
        "# 한 번에 입력받는 갯수와, 총 몇 단계로 이루어져있는 데이터를 받을지를 설정해야합니다.\n",
        "# 이를 위해 가로 픽셀수를 n_input 으로, 세로 픽셀수를 입력 단계인 n_step 으로 설정하였습니다.\n",
        "n_input = 28\n",
        "n_step = 28\n",
        "n_hidden = 128\n",
        "n_class = 10\n",
        "\n",
        "#########\n",
        "# 신경망 모델 구성\n",
        "######\n",
        "X = tf.placeholder(tf.float32, [None, n_step, n_input])\n",
        "Y = tf.placeholder(tf.float32, [None, n_class])\n",
        "\n",
        "W = tf.Variable(tf.random_normal([n_hidden, n_class]))\n",
        "b = tf.Variable(tf.random_normal([n_class]))\n",
        "\n",
        "# RNN 에 학습에 사용할 셀을 생성합니다\n",
        "# 다음 함수들을 사용하면 다른 구조의 셀로 간단하게 변경할 수 있습니다\n",
        "# BasicRNNCell,BasicLSTMCell,GRUCell\n",
        "cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
        "\n",
        "# RNN 신경망을 생성합니다\n",
        "# 원래는 다음과 같은 과정을 거쳐야 하지만\n",
        "# states = tf.zeros(batch_size)\n",
        "# for i in range(n_step):\n",
        "#     outputs, states = cell(X[[:, i]], states)\n",
        "# ...\n",
        "# 다음처럼 tf.nn.dynamic_rnn 함수를 사용하면\n",
        "# CNN 의 tf.nn.conv2d 함수처럼 간단하게 RNN 신경망을 만들어줍니다.\n",
        "# 겁나 매직!!\n",
        "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
        "\n",
        "# 결과를 Y의 다음 형식과 바꿔야 하기 때문에\n",
        "# Y : [batch_size, n_class]\n",
        "# outputs 의 형태를 이에 맞춰 변경해야합니다.\n",
        "# outputs : [batch_size, n_step, n_hidden]\n",
        "#        -> [n_step, batch_size, n_hidden]\n",
        "#        -> [batch_size, n_hidden]\n",
        "outputs = tf.transpose(outputs, [1, 0, 2])\n",
        "outputs = outputs[-1]\n",
        "model = tf.matmul(outputs, W) + b\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
        "\n",
        "#########\n",
        "# 신경망 모델 학습\n",
        "######\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "total_batch = int(mnist.train.num_examples/batch_size)\n",
        "\n",
        "for epoch in range(total_epoch):\n",
        "    total_cost = 0\n",
        "\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        # X 데이터를 RNN 입력 데이터에 맞게 [batch_size, n_step, n_input] 형태로 변환합니다.\n",
        "        batch_xs = batch_xs.reshape((batch_size, n_step, n_input))\n",
        "\n",
        "        _, cost_val = sess.run([optimizer, cost],\n",
        "                               feed_dict={X: batch_xs, Y: batch_ys})\n",
        "        total_cost += cost_val\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1),\n",
        "          'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
        "\n",
        "print('최적화 완료!')\n",
        "\n",
        "#########\n",
        "# 결과 확인\n",
        "######\n",
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "\n",
        "test_batch_size = len(mnist.test.images)\n",
        "test_xs = mnist.test.images.reshape(test_batch_size, n_step, n_input)\n",
        "test_ys = mnist.test.labels\n",
        "\n",
        "print('정확도:', sess.run(accuracy,\n",
        "                       feed_dict={X: test_xs, Y: test_ys}))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "Epoch: 0001 Avg. cost = 0.550\n",
            "Epoch: 0002 Avg. cost = 0.236\n",
            "Epoch: 0003 Avg. cost = 0.179\n",
            "Epoch: 0004 Avg. cost = 0.155\n",
            "Epoch: 0005 Avg. cost = 0.139\n",
            "Epoch: 0006 Avg. cost = 0.125\n",
            "Epoch: 0007 Avg. cost = 0.113\n",
            "Epoch: 0008 Avg. cost = 0.113\n",
            "Epoch: 0009 Avg. cost = 0.106\n",
            "Epoch: 0010 Avg. cost = 0.103\n",
            "Epoch: 0011 Avg. cost = 0.092\n",
            "Epoch: 0012 Avg. cost = 0.097\n",
            "Epoch: 0013 Avg. cost = 0.087\n",
            "Epoch: 0014 Avg. cost = 0.090\n",
            "Epoch: 0015 Avg. cost = 0.089\n",
            "Epoch: 0016 Avg. cost = 0.077\n",
            "Epoch: 0017 Avg. cost = 0.080\n",
            "Epoch: 0018 Avg. cost = 0.076\n",
            "Epoch: 0019 Avg. cost = 0.077\n",
            "Epoch: 0020 Avg. cost = 0.075\n",
            "Epoch: 0021 Avg. cost = 0.075\n",
            "Epoch: 0022 Avg. cost = 0.075\n",
            "Epoch: 0023 Avg. cost = 0.074\n",
            "Epoch: 0024 Avg. cost = 0.061\n",
            "Epoch: 0025 Avg. cost = 0.071\n",
            "Epoch: 0026 Avg. cost = 0.065\n",
            "Epoch: 0027 Avg. cost = 0.064\n",
            "Epoch: 0028 Avg. cost = 0.061\n",
            "Epoch: 0029 Avg. cost = 0.070\n",
            "Epoch: 0030 Avg. cost = 0.060\n",
            "최적화 완료!\n",
            "정확도: 0.977\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}